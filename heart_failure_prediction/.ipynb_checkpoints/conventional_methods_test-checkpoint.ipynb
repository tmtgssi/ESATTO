{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e8e4b6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from checkpoints/Support_Vector_Classifier.joblib...\n",
      "Classification Report for Support_Vector_Classifier.joblib:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77        27\n",
      "           1       0.63      0.71      0.67        17\n",
      "\n",
      "    accuracy                           0.73        44\n",
      "   macro avg       0.72      0.72      0.72        44\n",
      "weighted avg       0.73      0.73      0.73        44\n",
      "\n",
      "Loading model from checkpoints/Random_Forest.joblib...\n",
      "Classification Report for Random_Forest.joblib:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        27\n",
      "           1       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.77        44\n",
      "   macro avg       0.76      0.76      0.76        44\n",
      "weighted avg       0.77      0.77      0.77        44\n",
      "\n",
      "Loading model from checkpoints/XGBoost.joblib...\n",
      "Classification Report for XGBoost.joblib:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.67      0.77        27\n",
      "           1       0.62      0.88      0.73        17\n",
      "\n",
      "    accuracy                           0.75        44\n",
      "   macro avg       0.76      0.77      0.75        44\n",
      "weighted avg       0.79      0.75      0.75        44\n",
      "\n",
      "Loading model from checkpoints/Gradient_Boosting.joblib...\n",
      "Classification Report for Gradient_Boosting.joblib:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.81      0.81        27\n",
      "           1       0.71      0.71      0.71        17\n",
      "\n",
      "    accuracy                           0.77        44\n",
      "   macro avg       0.76      0.76      0.76        44\n",
      "weighted avg       0.77      0.77      0.77        44\n",
      "\n",
      "Loading model from checkpoints/LightGBM.joblib...\n",
      "Classification Report for LightGBM.joblib:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78        27\n",
      "           1       0.65      0.76      0.70        17\n",
      "\n",
      "    accuracy                           0.75        44\n",
      "   macro avg       0.74      0.75      0.74        44\n",
      "weighted avg       0.76      0.75      0.75        44\n",
      "\n",
      "Loading model from checkpoints/Logistic_Regression.joblib...\n",
      "Classification Report for Logistic_Regression.joblib:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.70      0.75        27\n",
      "           1       0.60      0.71      0.65        17\n",
      "\n",
      "    accuracy                           0.70        44\n",
      "   macro avg       0.70      0.70      0.70        44\n",
      "weighted avg       0.72      0.70      0.71        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "# Load the test data\n",
    "data = pd.read_csv('./tabular_dataset/test.csv')  # Replace with your test dataset\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = data.iloc[:, :-1].values  # Assume last column is the target\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Encode the target column if it's categorical\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Directory where the checkpoints are saved\n",
    "checkpoint_dir = 'checkpoints'\n",
    "\n",
    "# Get the list of saved models\n",
    "saved_models = [f for f in os.listdir(checkpoint_dir) if f.endswith('.joblib')]\n",
    "\n",
    "# Perform inference for each saved model\n",
    "for model_file in saved_models:\n",
    "    model_path = os.path.join(checkpoint_dir, model_file)\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "\n",
    "    # Load the model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # Perform inference\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(f\"Classification Report for {model_file}:\")\n",
    "    print(classification_report(y, y_pred))\n",
    "\n",
    "# Example: To use predictions from a specific model\n",
    "# specific_model = 'Logistic_Regression.joblib'  # Replace with the model you want\n",
    "# model = joblib.load(os.path.join(checkpoint_dir, specific_model))\n",
    "# y_pred_specific = model.predict(X)\n",
    "# print(\"Classification Report for specific model:\")\n",
    "# print(classification_report(y, y_pred_specific))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b361685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
